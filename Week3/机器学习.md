# 机器学习

## 线性回归

### 定义

​	在统计学中，线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。

​	回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。

#### 一元线性回归

一元线性回归包括自变量和可预测因变量，比如房屋面积与价格这一数据集，利用该数据集，我们的目的是训练一个线性方程，无限逼近所有数据点，然后利用该方程与给定的某一自变量（本例中为面积），可以预测因变量（本例中为房价）。

下面声明几种表示：

| 字母   | 意义   |
| ---- | ---- |
| m    | 数量   |
| x    | 输入   |
| y    | 输出   |
| h    | 假设   |



一元线性回归方程形式为：![屏幕快照 2017-04-08 19.29.37](/Users/tonyhsu/Desktop/屏幕快照 2017-04-08 19.29.37.png)



所以该回归方程和实际值得误差为：![屏幕快照 2017-04-08 19.31.56](/Users/tonyhsu/Desktop/屏幕快照 2017-04-08 19.31.56.png)

该公式是关于theta0，和theta1的二元函数，我们可以改变theta的取值，使得J函数的值最小，从而使我们的方程更加精确。

方法：给定theta0、theta1，使其沿梯度方向变化，![屏幕快照 2017-04-08 19.39.10](/Users/tonyhsu/Desktop/屏幕快照 2017-04-08 19.39.10.png)（a为学习率）

当theta不再变化时，则认为得到了J的最小值，此时theta为所求。

α为学习速率，当α过大时，有可能越过最小值，而α当过小时，容易造成迭代次数较多，收敛速度较慢。

#### 多元线性回归

大致与一元同理

不同点：

​	特征缩放：

​		1.除以最大值

​		2.x(i)=(x(i)-U(i))/s(i)                              s(i)=(max-min)或标准差

